<h1>Segmentação de plantas daninhas por meio de redes neurais convolucionais em imagens multiespectrais capturadas por VANT</h1>

> **Repositório com os dados, implementação e resultados da dissertação de mestrado (2023) FCT/UNESP**

<h2>Resumo</h2>
A presença de plantas daninhas ocasiona diversos prejuízos nas culturas agrícolas, podendo provocar diminuição na produtividade, redução da qualidade final do produto colhido, disseminação de pragas e doenças e até mesmo a perda total das lavouras. Desta forma, técnicas que permitam o reconhecimento automático das plantas daninhas são extremamente relevantes para a agricultura. Uma vez que se possa controlar essas plantas daninhas, é possível elevar tanto a qualidade quanto a quantidade da produção, além de reduzir os impactos ambientais por meio da diminuição no uso de defensivos agrícolas. A metodologia proposta utilizou a arquitetura U-Net com diferentes backbones de redes CNNs, a fim de realizar a segmentação de mamonas, planta daninha com maior ocorrência na cultura de cana-de-açúcar recém-plantada da área de estudo. Foi utilizado o VANT do modelo eBee X para embarcar a câmera Sequoia e capturar imagens multiespectrais. Por meio dessas imagens foram gerados ortofotomosaicos multiespectrais que serviram para criação da base de dados composta pelo ortofotomosaico com a aplicação do índice espectral NDVI e a máscara binária gerada por meio da vetorização das mamonas. Foram implementadas técnicas de data augmentation para aumentar o conjunto de dados e transfer learning para os backbones utilizarem pesos pré-treinados no conjunto de dados do ImageNet. Foi avaliado os dados de entrada contidos na base de dados e identificado um problema de desbalanceamento de classes que atrapalhou a segmentação das mamonas. Em vista dessa problemática, foi aplicada uma filtragem para selecionar menos dados que continham somente a classe background. O resultado foi uma melhora de 45,96% e 65,25%, respectivamente, para as métricas IoU e F1 Score. Também foram avaliados os desempenhos dos modelos por meio das métricas F1 Score, IoU e acurácia. O modelo com backbone ResNet-34 alcançou o melhor resultado com percentual de 69,08 F1 e 52,70 IoU no conjunto de teste, o modelo EfficientNet-b0 apresentou percentual de 64,53 F1 e 47,56 IoU e por fim o modelo Inception-V3 obteve o percentual de 60,22 F1 e 43,33 IoU no conjunto de teste. Todos os modelos apresentaram acurácia acima de 98%. Os resultados demonstraram um bom percentual de predição para a segmentação de mamonas em vista do conjunto de dados ser pequeno e pouco diversificado.

<h2>Abstract</h2>
The presence of weeds causes various damages in agricultural crops, such as decreased productivity, reduced quality of the final harvested product, dissemination of pests and diseases, and even the total loss of crops. Therefore, techniques that enable automatic recognition of weeds are extremely relevant to agriculture. Once these weeds can be controlled, it is possible to increase both the quality and quantity of production, as well as reduce environmental impacts through a reduction in the use of agricultural pesticides. The proposed methodology used the U-Net architecture with different CNN backbone networks to perform the segmentation of castor bean, a weed plant with the highest occurrence in newly planted sugarcane crops in the study area. The eBee X drone model was used to carry the Sequoia camera and capture multispectral images. These images were used to generate multispectral orthophotomosaics, which served as the basis for the database, composed of the orthophotomosaic with the application of the NDVI spectral index and the binary mask generated through the vectorization of the castor bean. Data augmentation techniques were implemented to increase the dataset and transfer learning to allow the backbones to use pre-trained weights from the ImageNet dataset. Input data contained in the database were evaluated, and an imbalance problem was identified that hindered the segmentation of the castor bean. To address this issue, filtering was applied to select fewer data that contained only the background class. The result was a 45.96% and 65.25% improvement, respectively, for the IoU and F1 Score metrics. The model performances were also evaluated through the F1 Score, IoU, and accuracy metrics. The ResNet-34 backbone model achieved the best result with a 69.08% F1 and 52.70% IoU in the test set, the EfficientNet-b0 model showed a 64.53% F1 and 47.56% IoU, and finally, the Inception-V3 model obtained a 60.22% F1 and 43.33% IoU in the test set. All models had accuracy above 98%. The results demonstrated a good prediction percentage for the segmentation of castor bean, considering that the dataset was small and lacked diversity.



